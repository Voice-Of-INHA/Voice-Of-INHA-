"use client"

import { useState, useRef, useEffect } from "react"
import HelpModal from "../components/modals/HelpModal"
import AnalysisControlPanel from "./panels/AnalysisControlPanel"
import RiskStatusPanel from "./panels/RiskStatusPanel"
import AnalysisLogPanel from "./panels/AnalysisLogPanel"
import SaveCallModal from "./panels/SaveCallModal"

// Safari êµ¬í˜• ë¸Œë¼ìš°ì € ì§€ì›ì„ ìœ„í•œ íƒ€ì… í™•ì¥
declare global {
  interface Window {
    webkitAudioContext?: typeof AudioContext
  }
}

interface AnalysisResult {
  risk: 'low' | 'medium' | 'high' | null
  riskScore: number
  keywords: string[]
  reason: string
  timestamp: number
}

interface BackendMessage {
  type: string
  transcript?: string
  is_final?: boolean
  speaker?: number
  segments?: Array<{
    speaker: number
    text: string
  }>
  risk_score?: number
  risk_level?: 'low' | 'medium' | 'high'
  analysis_reason?: string
  detected_keywords?: string[]
  message?: string
  error?: string
  detail?: string
  description?: string
  [key: string]: unknown
}

export default function AnalysisPage() {
  // í†µí•© ë…¹ìŒ/ë¶„ì„ ê´€ë ¨ ìƒíƒœ
  const [isActive, setIsActive] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [audioLevel, setAudioLevel] = useState(0)
  
  // ì—°ê²° ìƒíƒœ
  const [connectionStatus, setConnectionStatus] = useState<'disconnected' | 'connecting' | 'connected' | 'error'>('disconnected')
  const [analysisLog, setAnalysisLog] = useState<string>('')
  
  // ë¶„ì„ ê´€ë ¨ ìƒíƒœ
  const [analysisResult, setAnalysisResult] = useState<AnalysisResult>({
    risk: null,
    riskScore: 0,
    keywords: [],
    reason: '',
    timestamp: 0
  })
  
  // ëª¨ë‹¬ ê´€ë ¨ ìƒíƒœ
  const [showSaveModal, setShowSaveModal] = useState(false)
  const [showHelpModal, setShowHelpModal] = useState(false)
  const [phoneNumber, setPhoneNumber] = useState('')
  const [isSaving, setIsSaving] = useState(false)
  
  // Refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const socketRef = useRef<WebSocket | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const workletNodeRef = useRef<AudioWorkletNode | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const recordedChunksRef = useRef<Blob[]>([])

  // í™˜ê²½ ì„¤ì •
  const WS_URL = "ws://174.44.164.18:8000/ws/analysis"
  const CHUNK_MS = 500
  const TARGET_SR = 16000

  // í† ìŠ¤íŠ¸ ë©”ì‹œì§€ í‘œì‹œ í•¨ìˆ˜
  const showToast = (title: string, description: string, variant: 'default' | 'destructive' = 'default') => {
    console.log(`[${variant}] ${title}: ${description}`)
    if (variant === 'destructive') {
      alert(`ì˜¤ë¥˜: ${description}`)
    }
  }

  // ìœ„í—˜ë„ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬ ë ˆë²¨ ê³„ì‚°
  const getRiskLevel = (score: number): 'low' | 'medium' | 'high' => {
    if (score >= 70) return 'high'
    if (score >= 50) return 'medium'
    return 'low'
  }

  // AudioWorklet ì½”ë“œ ìƒì„±
  const buildWorkletBlobURL = () => {
    const workletCode = `
class ResamplerProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.buffer = [];
    this.sourceRate = sampleRate;
    this.targetRate = ${TARGET_SR};
    this.ratio = this.sourceRate / this.targetRate;
    this.chunkSamples = Math.floor(${TARGET_SR} * ${CHUNK_MS} / 1000);
  }
  downsampleMono(input) {
    const inLen = input.length;
    const outLen = Math.floor(inLen / this.ratio);
    const out = new Float32Array(outLen);
    let pos = 0;
    for (let i = 0; i < outLen; i++) {
      const nextPos = Math.min(Math.floor((i + 1) * this.ratio), inLen);
      let sum = 0, cnt = 0;
      for (; pos < nextPos; pos++, cnt++) sum += input[pos];
      out[i] = cnt ? (sum / cnt) : 0;
    }
    return out;
  }
  floatToInt16(f32) {
    const out = new Int16Array(f32.length);
    for (let i = 0; i < f32.length; i++) {
      let s = Math.max(-1, Math.min(1, f32[i]));
      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return out;
  }
  process(inputs) {
    if (!inputs || !inputs[0] || inputs[0].length === 0) return true;
    const ch0 = inputs[0][0];
    if (!ch0) return true;

    const down = this.downsampleMono(ch0);
    this.buffer.push(down);

    let total = 0; for (const b of this.buffer) total += b.length;
    if (total >= this.chunkSamples) {
      const merged = new Float32Array(total);
      let o = 0; for (const b of this.buffer) { merged.set(b, o); o += b.length; }
      this.buffer = [];

      let off = 0;
      while (off + this.chunkSamples <= merged.length) {
        const slice = merged.subarray(off, off + this.chunkSamples);
        const i16 = this.floatToInt16(slice);
        this.port.postMessage({ type: 'chunk', pcm16: i16.buffer }, [i16.buffer]);
        off += this.chunkSamples;
      }
      if (off < merged.length) this.buffer.push(merged.subarray(off));
    }
    return true;
  }
}
registerProcessor('resampler-processor', ResamplerProcessor);
    `
    return URL.createObjectURL(new Blob([workletCode], { type: "application/javascript" }))
  }

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ì¸¡ì •
  const measureAudioLevel = () => {
    if (analyserRef.current && isActive) {
      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
      analyserRef.current.getByteFrequencyData(dataArray)
      
      const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length
      setAudioLevel(Math.round(average / 255 * 100))
      
      animationFrameRef.current = requestAnimationFrame(measureAudioLevel)
    }
  }

  // ë…¹ìŒ ì‹œê°„ ì—…ë°ì´íŠ¸
  const startRecordingTimer = () => {
    setRecordingTime(0)
    recordingTimerRef.current = setInterval(() => {
      setRecordingTime(prev => prev + 1)
    }, 1000)
  }

  const stopRecordingTimer = () => {
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current)
      recordingTimerRef.current = null
    }
  }

  // WebSocket ì´ˆê¸°í™”
  const initializeWebSocket = (): Promise<WebSocket> => {
    return new Promise((resolve, reject) => {
      const socket = new WebSocket(WS_URL)
      socket.binaryType = "arraybuffer"
      socketRef.current = socket
      
      socket.onopen = () => {
        console.log("WebSocket ì—°ê²° ì„±ê³µ")
        setConnectionStatus('connected')
        showToast("ì—°ê²° ì„±ê³µ", "ë¶„ì„ ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        resolve(socket)
      }

      socket.onmessage = (event) => {
        try {
          const msg: BackendMessage = JSON.parse(event.data)
          console.log("ë°±ì—”ë“œ ë©”ì‹œì§€ ìˆ˜ì‹ :", msg)
          
          if (msg.type === "analysis_update") {
            let logText = ""
            
            if (msg.segments && Array.isArray(msg.segments) && msg.segments.length > 0) {
              const lines = msg.segments.map(s => `[SPK${s.speaker}] ${s.text || ""}`)
              logText = `${msg.is_final ? '[FINAL]' : '[PART]'} ${lines.join(' | ')}`
            } else {
              const spk = (msg.speaker !== undefined && msg.speaker !== null) ? `[SPK${msg.speaker}] ` : ""
              logText = `${msg.is_final ? '[FINAL]' : '[PART]'} ${spk}${msg.transcript || ""}`
            }
            
            if (msg.risk_score !== undefined) {
              logText += ` [ìœ„í—˜ë„: ${msg.risk_score}%]`
            }
            
            setAnalysisLog(prev => prev + logText + '\n')
            
            if (msg.is_final && msg.risk_score !== undefined) {
              updateAnalysisResult(msg)
            }
          } else if (msg.type === "error") {
            console.error("ë°±ì—”ë“œ ì˜¤ë¥˜:", msg)
            const errorMessage = msg.message || msg.error || msg.detail || msg.description || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
            setAnalysisLog(prev => prev + `ERROR: ${errorMessage}\n`)
          }
        } catch (error) {
          console.error("ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:", error)
          setAnalysisLog(prev => prev + `RAW: ${event.data}\n`)
        }
      }

      socket.onerror = (error) => {
        console.error("WebSocket ì˜¤ë¥˜:", error)
        setConnectionStatus('error')
        showToast("ì—°ê²° ì˜¤ë¥˜", "ë¶„ì„ ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "destructive")
        reject(error)
      }

      socket.onclose = () => {
        console.log("WebSocket ì—°ê²° ì¢…ë£Œ")
        setConnectionStatus('disconnected')
      }

      setTimeout(() => {
        if (socket.readyState === WebSocket.CONNECTING) {
          socket.close()
          setConnectionStatus('error')
          reject(new Error("ì—°ê²° íƒ€ì„ì•„ì›ƒ"))
        }
      }, 10000)
    })
  }

  // ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
  const updateAnalysisResult = (msg: BackendMessage) => {
    if (msg.risk_score === undefined) return

    const newRiskScore = Math.max(analysisResult.riskScore, msg.risk_score)
    
    const newResult: AnalysisResult = {
      risk: msg.risk_level || getRiskLevel(newRiskScore),
      riskScore: Math.round(newRiskScore),
      keywords: [...new Set([...analysisResult.keywords, ...(msg.detected_keywords || [])])],
      reason: msg.analysis_reason || analysisResult.reason,
      timestamp: Date.now()
    }
    
    setAnalysisResult(newResult)
  }

  // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  const initializeAudioStream = async (): Promise<MediaStream> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: false,
          sampleRate: 48000
        },
        video: false
      })
      
      streamRef.current = stream

      const AudioContextClass = window.AudioContext || window.webkitAudioContext || AudioContext
      audioContextRef.current = new AudioContextClass({ sampleRate: 48000 })
      
      analyserRef.current = audioContextRef.current.createAnalyser()
      analyserRef.current.fftSize = 256
      analyserRef.current.smoothingTimeConstant = 0.8
      
      const source = audioContextRef.current.createMediaStreamSource(stream)
      
      const blobURL = buildWorkletBlobURL()
      await audioContextRef.current.audioWorklet.addModule(blobURL)
      
      const workletNode = new AudioWorkletNode(audioContextRef.current, "resampler-processor")
      workletNodeRef.current = workletNode
      
      workletNode.port.onmessage = (ev) => {
        const d = ev.data
        if (d && d.type === "chunk" && socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
          socketRef.current.send(d.pcm16)
        }
      }
      
      source.connect(analyserRef.current)
      source.connect(workletNode)
      workletNode.connect(audioContextRef.current.destination)
      
      return stream
    } catch (error) {
      console.error("ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", error)
      throw new Error("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.")
    }
  }

  // MediaRecorder ì´ˆê¸°í™”
  const initializeMediaRecorder = (stream: MediaStream) => {
    const mimeType = MediaRecorder.isTypeSupported("audio/webm;codecs=opus") 
      ? "audio/webm;codecs=opus"
      : MediaRecorder.isTypeSupported("audio/webm")
      ? "audio/webm"
      : "audio/mp4"

    const mediaRecorder = new MediaRecorder(stream, {
      mimeType: mimeType,
      audioBitsPerSecond: 16000
    })

    mediaRecorderRef.current = mediaRecorder
    recordedChunksRef.current = []

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        recordedChunksRef.current.push(event.data)
      }
    }

    mediaRecorder.onstart = () => {
      console.log("ë…¹ìŒ ì‹œì‘")
    }

    mediaRecorder.onstop = () => {
      console.log("ë…¹ìŒ ì¤‘ì§€")
    }

    mediaRecorder.onerror = (error) => {
      console.error("MediaRecorder ì˜¤ë¥˜:", error)
      showToast("ë…¹ìŒ ì˜¤ë¥˜", "ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "destructive")
    }

    return mediaRecorder
  }

  // í†µí•© ì‹œì‘ í•¨ìˆ˜
  const startAnalysis = async () => {
    try {
      setConnectionStatus('connecting')
      setIsActive(true)
      setAnalysisLog('')
      
      setAnalysisResult({
        risk: null,
        riskScore: 0,
        keywords: [],
        reason: '',
        timestamp: 0
      })
      
      await initializeWebSocket()
      const stream = await initializeAudioStream()
      const mediaRecorder = initializeMediaRecorder(stream)
      
      mediaRecorder.start(250)
      measureAudioLevel()
      startRecordingTimer()
      
      showToast("ë¶„ì„ ì‹œì‘", "ì‹¤ì‹œê°„ ìŒì„± ë¶„ì„ ë° ë…¹ìŒì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    } catch (error) {
      console.error("ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:", error)
      setIsActive(false)
      setConnectionStatus('error')
      
      if (error instanceof Error) {
        showToast("ì‹œì‘ ì‹¤íŒ¨", error.message, "destructive")
      }
    }
  }

  // í†µí•© ì¤‘ì§€ í•¨ìˆ˜
  const stopAnalysis = () => {
    console.log("ë¶„ì„ ì¤‘ì§€")
    
    const finalRiskScore = analysisResult.riskScore
    
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop()
    }

    if (workletNodeRef.current) {
      try { workletNodeRef.current.disconnect() } catch {}
      workletNodeRef.current = null
    }
    
    if (audioContextRef.current) {
      try { audioContextRef.current.close() } catch {}
      audioContextRef.current = null
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }
    
    if (socketRef.current) {
      try { socketRef.current.close() } catch {}
      socketRef.current = null
    }

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
      animationFrameRef.current = null
    }

    stopRecordingTimer()
    setIsActive(false)
    setConnectionStatus('disconnected')
    setAudioLevel(0)
    
    if (finalRiskScore >= 50) {
      setShowSaveModal(true)
    } else {
      recordedChunksRef.current = []
      showToast("ë¶„ì„ ì™„ë£Œ", "ì•ˆì „í•œ í†µí™”ë¡œ íŒë‹¨ë˜ì–´ ë…¹ìŒì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    }
  }

  // í†µí™” ì €ì¥ í•¨ìˆ˜ (API route ì‚¬ìš©)
  const saveCall = async () => {
    if (!phoneNumber.trim()) {
      showToast("ì…ë ¥ ì˜¤ë¥˜", "ì „í™”ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "destructive")
      return
    }

    setIsSaving(true)

    try {
      const recordedBlob = new Blob(recordedChunksRef.current, { 
        type: 'audio/webm' 
      })

      const formData = new FormData()
      formData.append('audioFile', recordedBlob, `suspicious_call_${Date.now()}.webm`)
      formData.append('phoneNumber', phoneNumber.trim())

      console.log("ğŸ“¤ ì˜ì‹¬ í†µí™” ì €ì¥ ì‹œì‘:", phoneNumber.trim())

      const response = await fetch('/api/proxy', {
        method: 'POST',
        body: formData
      })

      if (!response.ok) {
        const errorText = await response.text()
        throw new Error(`ì—…ë¡œë“œ ì‹¤íŒ¨: ${response.status} - ${errorText}`)
      }

      const result = await response.text()
      console.log("âœ… ì˜ì‹¬ í†µí™” ì €ì¥ ì„±ê³µ:", result)

      showToast("ì €ì¥ ì™„ë£Œ", "ì˜ì‹¬ í†µí™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
      
      recordedChunksRef.current = []
      setPhoneNumber('')
      setShowSaveModal(false)

    } catch (error) {
      console.error("âŒ ì €ì¥ ì‹¤íŒ¨:", error)
      showToast("ì €ì¥ ì‹¤íŒ¨", "ì˜ì‹¬ í†µí™” ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "destructive")
    } finally {
      setIsSaving(false)
    }
  }

  // ì €ì¥ ê±´ë„ˆë›°ê¸°
  const skipSave = () => {
    recordedChunksRef.current = []
    setPhoneNumber('')
    setShowSaveModal(false)
    showToast("ì €ì¥ ê±´ë„ˆë›°ê¸°", "ë…¹ìŒ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
  }

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (isActive) {
        console.log("ë¶„ì„ ì¤‘ì§€")
        
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
          mediaRecorderRef.current.stop()
        }

        if (workletNodeRef.current) {
          try { workletNodeRef.current.disconnect() } catch {}
          workletNodeRef.current = null
        }
        
        if (audioContextRef.current) {
          try { audioContextRef.current.close() } catch {}
          audioContextRef.current = null
        }
        
        if (streamRef.current) {
          streamRef.current.getTracks().forEach(track => track.stop())
          streamRef.current = null
        }
        
        if (socketRef.current) {
          try { socketRef.current.close() } catch {}
          socketRef.current = null
        }

        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current)
          animationFrameRef.current = null
        }

        if (recordingTimerRef.current) {
          clearInterval(recordingTimerRef.current)
          recordingTimerRef.current = null
        }
      }
    }
  }, [isActive])

  return (
    <div className="min-h-screen bg-black flex flex-col p-4">
      {/* í—¤ë” */}
      <div className="flex items-center justify-between mb-6">
        <div className="flex items-center space-x-4">
          <button
            className="flex items-center text-white hover:text-gray-300 p-2 rounded-lg hover:bg-gray-800 transition-colors"
            onClick={() => window.history.back()}
          >
            â† ëŒì•„ê°€ê¸°
          </button>

          <button
            className="flex items-center text-white hover:text-gray-300 p-2 rounded-lg hover:bg-gray-800 transition-colors"
            onClick={() => setShowHelpModal(true)}
          >
            â“ ë„ì›€ë§
          </button>
        </div>
      </div>

      <div className="flex-1 flex flex-col items-center justify-center max-w-6xl mx-auto w-full">
        <h1 className="text-3xl font-bold text-white mb-8 text-center">
          ì‹¤ì‹œê°„ ë³´ì´ìŠ¤í”¼ì‹± ë¶„ì„ ì‹œìŠ¤í…œ
        </h1>

        <div className="grid grid-cols-1 lg:grid-cols-2 gap-6 w-full mb-6">
          {/* ë©”ì¸ ì»¨íŠ¸ë¡¤ */}
          <div className="bg-gray-900 border border-gray-700 rounded-lg shadow-lg">
            <div className="p-6">
              <AnalysisControlPanel
                isActive={isActive}
                connectionStatus={connectionStatus}
                recordingTime={recordingTime}
                audioLevel={audioLevel}
                onStartAnalysis={startAnalysis}
                onStopAnalysis={stopAnalysis}
              />
              
              <RiskStatusPanel
                analysisResult={analysisResult}
                isActive={isActive}
                connectionStatus={connectionStatus}
              />
            </div>
          </div>

          {/* ë¶„ì„ ë¡œê·¸ */}
          <AnalysisLogPanel analysisLog={analysisLog} />
        </div>
      </div>

      {/* ë„ì›€ë§ ëª¨ë‹¬ */}
      <HelpModal 
        isOpen={showHelpModal} 
        onClose={() => setShowHelpModal(false)} 
      />

      {/* ì €ì¥ ëª¨ë‹¬ */}
      <SaveCallModal
        isOpen={showSaveModal}
        analysisResult={analysisResult}
        phoneNumber={phoneNumber}
        isSaving={isSaving}
        onPhoneNumberChange={setPhoneNumber}
        onSave={saveCall}
        onSkip={skipSave}
      />
    </div>
  )
}